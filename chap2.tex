%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Preliminary Data Processing}
\section{Data Collecting and Cleaning}
The taxi GPS data used in this project is collected from the Computational Sensing Lab\cite{BPLL13} at Tsinghua University, Beijing, China. The data set contains approximately 83 million time-stamped taxi GPS records collected from 8,602 taxis in Beijing, from 1 May 2009 to 30 May 2009. The original data set consists of seven fields as shown in Table~\ref{Ta:orig_field}. The GPS coordinates in the data set are defined in the WGS-84\footnote{World Geodetic System} standard coordinate system, which is the reference coordinate system used by the GPS.

\begin{table}
\centering
\begin{tabular}{ | l | l | l | }\hline\textbf{Field} & \textbf{Explanation} \\ \hline
CUID & ID for each taxi \\ \hlineUNIX\_EPOCH & Unix timestamp in milliseconds since 1 January 1970\\ \hlineGPS\_LONG & Longitude encoded in WGS-84 multiplied by $10^{5}$\\ \hlineGPS\_LAT & Latitude encoded in WGS-84 multiplied by $10^{5}$ \\ \hlineHEAD & Heading direction in degrees with 0 denoting North\\ \hlineSPEED & Instantaneous speed in metres/second (m/s)\\ \hlineOCCUPIED & Binary indicator of whether the taxi is hired (1) or not (0)\\ \hline\end{tabular}\caption{Fields in the original data set}\label{Ta:orig_field}
\end{table}

The original data set comes in a binary file format. After the data was decoded and imported into a MySQL database, the first step in cleaning data was to delete all records with zero value in the SPEED field, since when a taxi is stationary it yields no valuable information about the \emph{trajectory} it is moving along. While being stationary could be due to a traffic jam, this kind of information is well captured by the time difference between the previous \emph{non-stationary} data point and the next \emph{non-stationary} data point. 

Moreover, all records must have a \emph{unique} pair of CUID and UNIX\_EPOCH fields, since it is not possible for a taxi to appear in two different locations at the same moment in time. This is possibly due to some errors in aggregating the original data set.

\section{Reverse Geocoding}
After the data set was cleaned, the next step was to map each GPS data point to a road segment, which is also known as \emph{reverse geocoding}. A number of algorithms\cite{MAP09} have been proposed for this purpose, but most of them require an additional GIS\footnote{Geographic Information System} database of the road network in Beijing. This project adopted an alternative strategy which leverages on the existing public API\footnote{Application Programming Interface} for reverse geocoding. 

Currently, a number of online mapping platforms provide reverse geocoding services as part of their developer APIs. Amongst others, Google Maps and Baidu Maps offer relatively stable and fast reverse geocoding services. However, due to the ``China GPS shift problem''\cite{GSHF17} where coordinates encoded in WGS-84 standard are required by regulations to be shifted by a large and variable amount when displayed on a street map, Google Maps is not able to display a GPS data point correctly. 

Baidu Maps, on the other hand, has been using their own coordinate system called BD-09 which is an improved version of the Chinese official coordinate system, GCJ-02. Baidu provides a set of APIs to convert WGS-84 coordinates into BD-09 ones. To store the converted coordinates as well as the street names obtained from reverse geocoding, four new fields were added to the original data set as shown in Table~\ref{Ta:addtional_field}.

\begin{table}
\centering
\begin{tabular}{ | l | l | l | }\hline\textbf{Field} & \textbf{Explanation} \\ \hline
DataUnitID & Nominal primary key for each record \\ \hlineBD09\_LONG & Longitude encoded in BD-09 format\\ \hlineBD09\_LAT & Latitude encoded in BD-09 format\\ \hlineSTREET & Street name\\ \hline\end{tabular}\caption{Additional fields added to data set}\label{Ta:addtional_field}
\end{table}

In order to use Baidu APIs for reverse geocoding, the following system architecture was set up as shown in Figure~\ref{Fig:basic_architecture}. The Apache HTTP server hides the MySQL database and sends HTTP POST request to Baidu Maps Web API to get converted coordinates. Then it updates the database through PHP \emph{mysqli} utilitity. 

\begin{figure}[h]
\includegraphics{basic_architecture}
\centering
\caption{Basic system architecture}\label{Fig:basic_architecture}
\end{figure}

After the coordinates were converted from WGS-84 format to BD-09 format, Baidu Maps Web API was used to reverse geocode all GPS data points. However, the system architecture was slightly changed, to accommodate the change in technology used. For reverse geocoding, AJAX\footnote{Asynchronous JavaScript and XML} was used to communicate with the Baidu Maps Web API for speed and unlimited number of requests per day. Therefore, one additional layer was added to the existing system architecture as shown in Figure~\ref{Fig:ajax_architecture}. 

\begin{figure}[h]
\includegraphics{ajax_architecture}
\centering
\caption{Augmented system architecture}\label{Fig:ajax_architecture}
\end{figure}

Executed in a web browser environment, AJAX sent HTTP POST requests to the Apache HTTP server to fetch the converted coordinates in BD-09 format which were subsequently sent to the Baidu Maps Web API server \emph{asynchronously} via HTTP GET requests. Once the server responded with the name of the road segment, AJAX updated the database by sending another HTTP POST request to the Apache HTTP server. The asynchronous nature of this architecture, however, caused a few problems which are addressed in Section~\ref{outlier_detecting}. 

\section{Outlier Detecting}\label{outlier_detecting}
The Baidu Maps Web API for reverse geocoding is stable and fast, but does not work with no errors. Sometimes, a GPS data point may refer to a location between a main road and a side road when plotted or it is just mapped to a street that Baidu Maps does not recognise. In neither case will Baidu Maps Web API produce a correct reverse geocoding. Moreover, the reverse geocoding process is asynchronous, which means that it is being performed in the background in parallel with the main application thread. Therefore, it is inevitable that some street names may get lost when the records are being updated or a record is updated with a wrong street name. 

A record with this kind of error is known as an \emph{outlier} and must be removed. This project proposes a novel outlier detection method based on unsupervised learning. The rationale behind this method is based on the following theorem.

\begin{defn}[\emph{Reasonable reverse geocoder}]
A reasonable reverse geocoder always gives its best matching from a GPS data point to a street whenever possible and has an accuracy at least 50\%.
\end{defn}

\begin{theorem}[\emph{Majority Clustering Theorem}]
If a \emph{reasonable reverse geocoder} is used to reverse geocode a set of GPS data points which are mapped to a particular street \emph{in reality}, then, when plotted on a map, majority (at least 50\%) of the points must be clustered together to form a rough shape that is similar to the shape of the street that they are supposed to be mapped to. 
\end{theorem}

\begin{proof}
Proof by contradiction. Assume, for the sake of contradiction, majority (at least 50\%) of the data points that are \emph{indeed} located on the same street are scattered arbitrarily on a map after being reverse geocoded by a reasonable reverse geocoder. In particular, when plotted on a map, majority of them do not form a similar shape to that of the street they are supposed to be mapped to. Then, the majority must have been erroneously mapped to some other streets because no single street can cover the whole city. Thus, the reasonable reverse geocoder has only achieved an accuracy less 50\%, which contradicts the definition of a reasonable reverse geocoder. 
\end{proof}

Apparently, Baidu Maps Web API is a reasonable reverse geocoder because it is designed to be used by developers working Baidu Maps and has an accuracy larger than 50\%. Therefore, if a set of points belong to a particular street, after reverse geocoded by Baidu Maps Web API, majority of them should be clustered to assume a rough shape of that street. Based on this realisation, an unsupervised learning technique --- clustering can be used to separate the correctly mapped data points from outliers. 

Many clustering techniques are available. Since each record can be represented graphically by a point on a 2-D plane with BD09\_LAT as the $x$ axis and BD09\_LONG as the $y$ axis, a \textbf{self-organising feature map}\cite{TK82} seems to be an appropriate technique to use. 

A self-organising feature map is a type of artificial neural network. It consists of a pre-defined number of interconnected neurons randomly scattered among the data points at the begin of training. A neuron gradually moves to the centroid of the data cluster it represents as the training goes. Once the training stops, all data points near to a particular neuron, in terms of Euclidean distance\footnote{Other distance measures are also possible}, are assigned to the cluster that neuron represents. 